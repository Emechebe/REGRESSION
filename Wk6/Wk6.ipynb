{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting house prices using the k nearest neighbour regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1478105154.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to emechebe@ohsu.edu and will expire on June 11, 2017.\n"
     ]
    }
   ],
   "source": [
    "sales = graphlab.SFrame('kc_house_data_small.gl/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">id</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">date</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">price</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">bedrooms</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">bathrooms</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_living</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_lot</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">floors</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">waterfront</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7129300520</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-10-13 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">221900</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1180.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5650</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6414100192</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-12-09 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">538000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.25</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2570.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7242</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5631500400</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-02-25 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">180000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">770.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2487200875</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-12-09 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">604000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1960.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1954400510</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-02-18 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">510000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1680.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8080</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2008000270</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-01-15 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">291850</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1060.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9711</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2414600126</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-04-15 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">229500</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1780.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7470</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1736800520</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-04-03 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">662500</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3560.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9796</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9297300055</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-01-24 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">650000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2950.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6865200140</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-05-29 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">485000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1600.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4300</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">view</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">condition</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">grade</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_above</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_basement</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">yr_built</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">yr_renovated</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">zipcode</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">lat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1180</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1955</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98178</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.51123398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2170</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">400</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1951</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1991</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98125</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.72102274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">770</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1933</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98028</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.73792661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1050</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">910</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1965</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98136</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.52082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1680</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1987</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98074</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.61681228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1060</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1963</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98198</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.40949984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1050</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">730</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1960</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98146</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.51229381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1860</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1700</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1965</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98007</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.60065993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1980</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">970</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1979</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98126</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.57136955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1600</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1916</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98103</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.66478645</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">long</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_living15</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_lot15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.25677536</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1340.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.3188624</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1690.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.23319601</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2720.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.39318505</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1360.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.04490059</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1800.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.31457273</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1650.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.33659507</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1780.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.14529566</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2210.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.37541218</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2140.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.34281613</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1610.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4300.0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[8703 rows x 21 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tid\tstr\n",
       "\tdate\tdatetime\n",
       "\tprice\tint\n",
       "\tbedrooms\tfloat\n",
       "\tbathrooms\tfloat\n",
       "\tsqft_living\tfloat\n",
       "\tsqft_lot\tint\n",
       "\tfloors\tfloat\n",
       "\twaterfront\tint\n",
       "\tview\tint\n",
       "\tcondition\tint\n",
       "\tgrade\tint\n",
       "\tsqft_above\tint\n",
       "\tsqft_basement\tint\n",
       "\tyr_built\tint\n",
       "\tyr_renovated\tint\n",
       "\tzipcode\tstr\n",
       "\tlat\tfloat\n",
       "\tlong\tfloat\n",
       "\tsqft_living15\tfloat\n",
       "\tsqft_lot15\tfloat\n",
       "\n",
       "Rows: 8703\n",
       "\n",
       "Data:\n",
       "+------------+---------------------------+--------+----------+-----------+\n",
       "|     id     |            date           | price  | bedrooms | bathrooms |\n",
       "+------------+---------------------------+--------+----------+-----------+\n",
       "| 7129300520 | 2014-10-13 00:00:00+00:00 | 221900 |   3.0    |    1.0    |\n",
       "| 6414100192 | 2014-12-09 00:00:00+00:00 | 538000 |   3.0    |    2.25   |\n",
       "| 5631500400 | 2015-02-25 00:00:00+00:00 | 180000 |   2.0    |    1.0    |\n",
       "| 2487200875 | 2014-12-09 00:00:00+00:00 | 604000 |   4.0    |    3.0    |\n",
       "| 1954400510 | 2015-02-18 00:00:00+00:00 | 510000 |   3.0    |    2.0    |\n",
       "| 2008000270 | 2015-01-15 00:00:00+00:00 | 291850 |   3.0    |    1.5    |\n",
       "| 2414600126 | 2015-04-15 00:00:00+00:00 | 229500 |   3.0    |    1.0    |\n",
       "| 1736800520 | 2015-04-03 00:00:00+00:00 | 662500 |   3.0    |    2.5    |\n",
       "| 9297300055 | 2015-01-24 00:00:00+00:00 | 650000 |   4.0    |    3.0    |\n",
       "| 6865200140 | 2014-05-29 00:00:00+00:00 | 485000 |   4.0    |    1.0    |\n",
       "+------------+---------------------------+--------+----------+-----------+\n",
       "+-------------+----------+--------+------------+------+-----------+-------+------------+\n",
       "| sqft_living | sqft_lot | floors | waterfront | view | condition | grade | sqft_above |\n",
       "+-------------+----------+--------+------------+------+-----------+-------+------------+\n",
       "|    1180.0   |   5650   |  1.0   |     0      |  0   |     3     |   7   |    1180    |\n",
       "|    2570.0   |   7242   |  2.0   |     0      |  0   |     3     |   7   |    2170    |\n",
       "|    770.0    |  10000   |  1.0   |     0      |  0   |     3     |   6   |    770     |\n",
       "|    1960.0   |   5000   |  1.0   |     0      |  0   |     5     |   7   |    1050    |\n",
       "|    1680.0   |   8080   |  1.0   |     0      |  0   |     3     |   8   |    1680    |\n",
       "|    1060.0   |   9711   |  1.0   |     0      |  0   |     3     |   7   |    1060    |\n",
       "|    1780.0   |   7470   |  1.0   |     0      |  0   |     3     |   7   |    1050    |\n",
       "|    3560.0   |   9796   |  1.0   |     0      |  0   |     3     |   8   |    1860    |\n",
       "|    2950.0   |   5000   |  2.0   |     0      |  3   |     3     |   9   |    1980    |\n",
       "|    1600.0   |   4300   |  1.5   |     0      |  0   |     4     |   7   |    1600    |\n",
       "+-------------+----------+--------+------------+------+-----------+-------+------------+\n",
       "+---------------+----------+--------------+---------+-------------+\n",
       "| sqft_basement | yr_built | yr_renovated | zipcode |     lat     |\n",
       "+---------------+----------+--------------+---------+-------------+\n",
       "|       0       |   1955   |      0       |  98178  | 47.51123398 |\n",
       "|      400      |   1951   |     1991     |  98125  | 47.72102274 |\n",
       "|       0       |   1933   |      0       |  98028  | 47.73792661 |\n",
       "|      910      |   1965   |      0       |  98136  |   47.52082  |\n",
       "|       0       |   1987   |      0       |  98074  | 47.61681228 |\n",
       "|       0       |   1963   |      0       |  98198  | 47.40949984 |\n",
       "|      730      |   1960   |      0       |  98146  | 47.51229381 |\n",
       "|      1700     |   1965   |      0       |  98007  | 47.60065993 |\n",
       "|      970      |   1979   |      0       |  98126  | 47.57136955 |\n",
       "|       0       |   1916   |      0       |  98103  | 47.66478645 |\n",
       "+---------------+----------+--------------+---------+-------------+\n",
       "+---------------+---------------+-----+\n",
       "|      long     | sqft_living15 | ... |\n",
       "+---------------+---------------+-----+\n",
       "| -122.25677536 |     1340.0    | ... |\n",
       "|  -122.3188624 |     1690.0    | ... |\n",
       "| -122.23319601 |     2720.0    | ... |\n",
       "| -122.39318505 |     1360.0    | ... |\n",
       "| -122.04490059 |     1800.0    | ... |\n",
       "| -122.31457273 |     1650.0    | ... |\n",
       "| -122.33659507 |     1780.0    | ... |\n",
       "| -122.14529566 |     2210.0    | ... |\n",
       "| -122.37541218 |     2140.0    | ... |\n",
       "| -122.34281613 |     1610.0    | ... |\n",
       "+---------------+---------------+-----+\n",
       "[8703 rows x 21 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we want to predict price using the k nearest neighbour technique\n",
    "# That is given a query, we want to calculate a distance metric of our query and each house in the data set\n",
    "# Then based on the result of the distance metric , we select a k number of houses that are most similar to query\n",
    "# Then we use thier prices to estimate the price of our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matrix manipulation requires numpy\n",
    "# Import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For distance metric, it is always better to use normalized values.\n",
    "# This is because if the scale of one feature is just larger in magnitude than other features,\n",
    "# that difference in magnitude might exert an undue influence on the distance score.\n",
    "# For instance, the no of floors is from a scale of 1 to 10 (hypothetically)\n",
    "# while sqft is in the thousands. Does that mean that sqft is more important than floor? Well you dont know that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are various ways of normalization.\n",
    "# The way that we chose to normalize here is to calculate the magnitude of the vector \n",
    "# and dividing all the observations by this magnitude.\n",
    "# Now whats this magnitude we talk about?\n",
    "# The magnitude of a vector is given by :\n",
    "# squaring each observation\n",
    "# Taking the sum of all the squared values\n",
    "# Then taking the square root and that value is termed as the magnitude of the vector\n",
    "# We divide all the observations with this value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So wrote a function that takes a matrix of values and returns normalized values\n",
    "# Function that takes an array and returns the normalized scores\n",
    "# A numpy function called linalg.norm returns the magnitude of the vector\n",
    "# Now I can use it to divide the feature matrix and that will be our normalized data set\n",
    "# Now write this function called normalize_features\n",
    "# In this function we did this computation column wise. So we have a norm value for each column (ie for each feature)\n",
    "# We have 18 features , so our norm matrix will contain 18 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    # Use the linalg.norm function to return the magnitude of the vector\n",
    "    # This is done column wise and thus we set the axis to 0\n",
    "    norms = np.linalg.norm(feature_matrix, axis=0) \n",
    "    # Use the norms to now divide all the values by this norm\n",
    "    features = feature_matrix / norms\n",
    "    # Return the normalized data and also the norm value that we used to generate \n",
    "    return features, norms\n",
    "\n",
    "    # Note we will use the same norm value to get the normalized value for the test data and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into training, test, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_and_validation, test) = sales.random_split(.8, seed=1) # initial train/test split\n",
    "(train, validation) = train_and_validation.random_split(.8, seed=1) # split training set into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our data is in Sframe and for our data manipulation we need the data to be in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using all of the numerical inputs listed in feature_list, \n",
    "# transform the training, test, and validation SFrames into Numpy arrays\n",
    "# This means I need the get_numpy_data function we wrote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features,output):\n",
    "    # This function takes a data set(data_sframe), a list of features (features) and what you want to predict as a string.\n",
    "    # It returns back 2 numpy array that has the measurements of your selected features (feature_matrix)\n",
    "    #  The other array is what you want to predict (output array)\n",
    "    # Using the data we have, add a constant variable for intercept and select the features you want to use\n",
    "    data_sframe['constant'] = 1 # add a constant column to an SFrame. This is for intercept\n",
    "    features = ['constant'] + features  # Prepending the new constant variable to the features also\n",
    "    features_sframe = data_sframe[features] # Getting the newly formed user selected features Sframe\n",
    "    features_matrix = features_sframe.to_numpy() # Converting the features Sframe data to a numpy array data\n",
    "    output_sarray = data_sframe[output]\n",
    "    output_array = output_sarray.to_numpy()\n",
    "    return (features_matrix,output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I will be using the entire features for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = ['bedrooms',  \n",
    "                'bathrooms',  \n",
    "                'sqft_living',  \n",
    "                'sqft_lot',  \n",
    "                'floors',\n",
    "                'waterfront',  \n",
    "                'view',  \n",
    "                'condition',  \n",
    "                'grade',  \n",
    "                'sqft_above',  \n",
    "                'sqft_basement',\n",
    "                'yr_built',  \n",
    "                'yr_renovated',  \n",
    "                'lat',  \n",
    "                'long',  \n",
    "                'sqft_living15',  \n",
    "                'sqft_lot15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Arranging all my data sets into numpy arrays using the get_numpy_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train, output_train = get_numpy_data(train, feature_list, 'price')\n",
    "features_test, output_test = get_numpy_data(test, feature_list, 'price')\n",
    "features_valid, output_valid = get_numpy_data(validation, feature_list, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now the k nearest neighbour involves calculation of distances of query from observations in the data set\n",
    "# For this you want your data to be all normalized or else a column of data with very large values of measures\n",
    "# might exert undue influence in the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize train data\n",
    "# Return the normalized data and also the norm value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train, norms = normalize_features(features_train) # normalize training set features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: Make sure to store the norms of the features in the training set. \n",
    "# The features in the test and validation sets must be divided by these same norms, \n",
    "# so that the training, test, and validation sets are normalized consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now use the norms from training data to normalize our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_test = features_test / norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Also , use the norms from training data to normalize our validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_valid = features_valid / norms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we have normalized values, we can now start calculating distances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets compute the distance between just two houses\n",
    "# Lets use the query house as the first house in the test data set\n",
    "# And the subject is the 10th house in the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets take a look at the first house (ie query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01345102,  0.01551285,  0.01807473,  0.01759212,  0.00160518,\n",
       "        0.017059  ,  0.        ,  0.05102365,  0.0116321 ,  0.01564352,\n",
       "        0.01362084,  0.02481682,  0.01350306,  0.        ,  0.01345386,\n",
       "       -0.01346927,  0.01375926,  0.0016225 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets take a look at the 10th house "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01345102,  0.01163464,  0.00602491,  0.0083488 ,  0.00050756,\n",
       "        0.01279425,  0.        ,  0.        ,  0.01938684,  0.01390535,\n",
       "        0.0096309 ,  0.        ,  0.01302544,  0.        ,  0.01346821,\n",
       "       -0.01346254,  0.01195898,  0.00156612])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What is the Euclidean distance between the query house and the 10th house of the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The formula for Euclidean distance is :\n",
    "# Get the difference between each observation for each feature\n",
    "# Square those differences to get rid of direction\n",
    "# Then sum over all the squared diffences\n",
    "# Finally take the square root of the sum of the squared differences\n",
    "# The value you get is an indication of how similar house 1 is to house 10 using the Euclidean distance as a measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Difference = features_test[0] - features_train[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   3.87821276e-03,   1.20498190e-02,\n",
       "         9.24331842e-03,   1.09762322e-03,   4.26475103e-03,\n",
       "         0.00000000e+00,   5.10236549e-02,  -7.75473450e-03,\n",
       "         1.73816863e-03,   3.98994223e-03,   2.48168183e-02,\n",
       "         4.77622244e-04,   0.00000000e+00,  -1.43460647e-05,\n",
       "        -6.72204960e-06,   1.80027678e-03,   5.63818921e-05])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Squaring the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Squared_Differences = Difference ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   1.50405342e-05,   1.45198139e-04,\n",
       "         8.54389355e-05,   1.20477673e-06,   1.81881013e-05,\n",
       "         0.00000000e+00,   2.60341336e-03,   6.01359072e-05,\n",
       "         3.02123018e-06,   1.59196390e-05,   6.15874470e-04,\n",
       "         2.28123008e-07,   0.00000000e+00,   2.05809573e-10,\n",
       "         4.51859508e-11,   3.24099649e-06,   3.17891776e-09])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Squared_Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summing over all squared differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sum_of_squared_differences = np.sum(Squared_Differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0035669076464328198"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sum_of_squared_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taking the square root to get the Euclidean distance between the two houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Euclidean_distance = np.sqrt(Sum_of_squared_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059723593716661257"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Euclidean_distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ok this was just computing one distance.\n",
    "# We now want to compute multiple distances (ie query versus more than one house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Of course, to do nearest neighbor regression, \n",
    "# we need to compute the distance between our query house and all houses in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To visualize this nearest-neighbor search, \n",
    "# let's first compute the distance from our query house (features_test[0]) \n",
    "# to the first 10 houses of the training set (features_train[0:10]) \n",
    "# and then search for the nearest neighbor within this small set of houses. \n",
    "# Through restricting ourselves to a small set of houses to begin with, \n",
    "# we can visually scan the list of 10 distances to verify that our code for finding the nearest neighbor is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a loop to compute the Euclidean distance from the query house \n",
    "# to each of the first 10 houses in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Euclidean_distance():\n",
    "    for i in xrange(10):\n",
    "        Difference = features_test[0] - features_train[i]\n",
    "        Squared_Differences = Difference ** 2\n",
    "        Sum_of_squared_differences = np.sum(Squared_Differences)\n",
    "        Euclidean_distance = np.sqrt(Sum_of_squared_differences)\n",
    "        print Euclidean_distance, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.060274709173 0\n",
      "0.0854688114883 1\n",
      "0.0614994643712 2\n",
      "0.0534027397882 3\n",
      "0.0584448406394 4\n",
      "0.0598792151018 5\n",
      "0.0546314049726 6\n",
      "0.0554310832416 7\n",
      "0.052383627841 8\n",
      "0.0597235937167 9\n"
     ]
    }
   ],
   "source": [
    "Euclidean_distance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ninth house seems to be the closest house to the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that worked!\n",
    "# We set up a loop that went through the computation element by element\n",
    "# i.e features_test[0] - features_test[i]\n",
    "# For small data set, thats fine. For big data set that can be computationally expensive.\n",
    "# Luckily we can perform operations on whole vectors using Numpy,\n",
    "# as opposed to going through the vector row by row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For instance, lets say we want the difference between query house and the first ten houses\n",
    "# Instead of going by loop, like we did last time\n",
    "# we just take the entire vector of the query and subtract from the entire vector of query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Differences = features_train[0:10] - features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,  -3.87821276e-03,  -1.20498190e-02,\n",
       "         -1.05552733e-02,   2.08673616e-04,  -8.52950206e-03,\n",
       "          0.00000000e+00,  -5.10236549e-02,   0.00000000e+00,\n",
       "         -3.47633726e-03,  -5.50336860e-03,  -2.48168183e-02,\n",
       "         -1.63756198e-04,   0.00000000e+00,  -1.70072004e-05,\n",
       "          1.30577772e-05,  -5.14364795e-03,   6.69281453e-04],\n",
       "       [  0.00000000e+00,  -3.87821276e-03,  -4.51868214e-03,\n",
       "         -2.26610387e-03,   7.19763456e-04,   0.00000000e+00,\n",
       "          0.00000000e+00,  -5.10236549e-02,   0.00000000e+00,\n",
       "         -3.47633726e-03,   1.30705004e-03,  -1.45830788e-02,\n",
       "         -1.91048898e-04,   6.65082271e-02,   4.23240653e-05,\n",
       "          6.22415897e-06,  -2.89330197e-03,   1.47606982e-03],\n",
       "       [  0.00000000e+00,  -7.75642553e-03,  -1.20498190e-02,\n",
       "         -1.30002801e-02,   1.60518166e-03,  -8.52950206e-03,\n",
       "          0.00000000e+00,  -5.10236549e-02,   0.00000000e+00,\n",
       "         -5.21450589e-03,  -8.32384500e-03,  -2.48168183e-02,\n",
       "         -3.13866046e-04,   0.00000000e+00,   4.71047219e-05,\n",
       "          1.56530415e-05,   3.72914476e-03,   1.64764925e-03],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         -5.90379693e-03,   0.00000000e+00,  -8.52950206e-03,\n",
       "          0.00000000e+00,  -5.10236549e-02,   7.75473450e-03,\n",
       "         -3.47633726e-03,  -6.39766599e-03,  -1.53506093e-03,\n",
       "         -9.55244489e-05,   0.00000000e+00,  -1.42961367e-05,\n",
       "         -1.95617327e-06,  -5.01505675e-03,   4.05625123e-04],\n",
       "       [  0.00000000e+00,  -3.87821276e-03,  -6.02490952e-03,\n",
       "         -7.57355768e-03,   9.88791902e-04,  -8.52950206e-03,\n",
       "          0.00000000e+00,  -5.10236549e-02,   0.00000000e+00,\n",
       "         -1.73816863e-03,  -2.06376322e-03,  -2.48168183e-02,\n",
       "          5.45853994e-05,   0.00000000e+00,   1.28518548e-05,\n",
       "          3.63778016e-05,  -2.18605038e-03,   1.42090481e-03],\n",
       "       [  0.00000000e+00,  -3.87821276e-03,  -9.03736428e-03,\n",
       "         -1.12708850e-02,   1.51240216e-03,  -8.52950206e-03,\n",
       "          0.00000000e+00,  -5.10236549e-02,   0.00000000e+00,\n",
       "         -3.47633726e-03,  -6.32887389e-03,  -2.48168183e-02,\n",
       "         -1.09170799e-04,   0.00000000e+00,  -4.57790721e-05,\n",
       "          6.69630207e-06,  -3.15048437e-03,   2.31652508e-03],\n",
       "       [  0.00000000e+00,  -3.87821276e-03,  -1.20498190e-02,\n",
       "         -6.97721455e-03,   7.92959740e-04,  -8.52950206e-03,\n",
       "          0.00000000e+00,  -5.10236549e-02,   0.00000000e+00,\n",
       "         -3.47633726e-03,  -6.39766599e-03,  -6.14024370e-03,\n",
       "         -1.29640323e-04,   0.00000000e+00,  -1.67074653e-05,\n",
       "          4.27241032e-06,  -2.31464158e-03,   1.66833613e-03],\n",
       "       [  0.00000000e+00,  -3.87821276e-03,  -3.01245476e-03,\n",
       "          3.63769306e-03,   1.53969025e-03,  -8.52950206e-03,\n",
       "          0.00000000e+00,  -5.10236549e-02,   0.00000000e+00,\n",
       "         -1.73816863e-03,  -8.25505290e-04,   1.86765746e-02,\n",
       "         -9.55244489e-05,   0.00000000e+00,   8.28373894e-06,\n",
       "          2.53278050e-05,   4.50069195e-04,   1.99770373e-03],\n",
       "       [  0.00000000e+00,  -3.87821276e-03,  -7.53113690e-03,\n",
       "         -2.98171562e-03,  -7.41272890e-04,   0.00000000e+00,\n",
       "          0.00000000e+00,  -5.10236549e-02,   0.00000000e+00,\n",
       "         -1.73816863e-03,  -1.58221847e-03,  -6.90777416e-03,\n",
       "         -4.36683195e-04,   0.00000000e+00,   1.90017767e-05,\n",
       "          1.71222272e-06,  -2.44323277e-03,  -1.73201928e-04],\n",
       "       [  0.00000000e+00,  -3.87821276e-03,  -1.20498190e-02,\n",
       "         -9.24331842e-03,  -1.09762322e-03,  -4.26475103e-03,\n",
       "          0.00000000e+00,  -5.10236549e-02,   7.75473450e-03,\n",
       "         -1.73816863e-03,  -3.98994223e-03,  -2.48168183e-02,\n",
       "         -4.77622244e-04,   0.00000000e+00,   1.43460647e-05,\n",
       "          6.72204960e-06,  -1.80027678e-03,  -5.63818921e-05]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = features_train[0:3] - features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print results[2] - (features_train[2]-features_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So what we have now is the same thing we would have if we set a for loop\n",
    "# and go through each vector row by row and compute differences\n",
    "# This is way easy as we just do it in one line of code\n",
    "# and more importantly, it is faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform 1 nearest neighbour regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we have to calculate the difference of two vectors using Numpy\n",
    "# So lets get the difference between our query and all the house in the training data set\n",
    "# Lets call this the DifferenceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DifferenceMatrix = features_train - features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,  -3.87821276e-03,  -1.20498190e-02, ...,\n",
       "          1.30577772e-05,  -5.14364795e-03,   6.69281453e-04],\n",
       "       [  0.00000000e+00,  -3.87821276e-03,  -4.51868214e-03, ...,\n",
       "          6.22415897e-06,  -2.89330197e-03,   1.47606982e-03],\n",
       "       [  0.00000000e+00,  -7.75642553e-03,  -1.20498190e-02, ...,\n",
       "          1.56530415e-05,   3.72914476e-03,   1.64764925e-03],\n",
       "       ..., \n",
       "       [  0.00000000e+00,  -3.87821276e-03,  -3.01245476e-03, ...,\n",
       "          5.43940273e-05,   8.35842791e-04,   7.02137088e-04],\n",
       "       [  0.00000000e+00,   0.00000000e+00,  -3.01245476e-03, ...,\n",
       "          2.28925105e-05,   2.44323277e-03,   8.20579624e-04],\n",
       "       [  0.00000000e+00,  -3.87821276e-03,  -3.01245476e-03, ...,\n",
       "          3.22568982e-06,  -3.92203156e-03,  -1.01041218e-03]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DifferenceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that we have all the differences, we can now go on and calculate the Euclidean distance \n",
    "# of our query to all the houses in our data set by just taking the square of the differences\n",
    "#taking the sum of the squared differences and then taking the square root of this sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets take the sum of the last row in our difference matrix.\n",
    "# This is a check to see if our code is working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0934339605842\n"
     ]
    }
   ],
   "source": [
    "print DifferenceMatrix[-1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It returned the expected result, so proceed with programming assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So onto getting the Euclidean distance from the DistanceMatrix we just calculated\n",
    "# First we square the Differences to remove direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Squared_Differences = DifferenceMatrix ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Then we take the sum of the Squared differences and we do this row by row \n",
    "# Thus our result will be a 1D vector whose len is equal to the len of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sum_Squared_Differences = np.sum(Squared_Differences, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we can take the square root to get the Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Euclidean_distance = np.sqrt(Sum_Squared_Differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now lets test our computation by looking at the distance between our query and our 100th house in the training\n",
    "# The value should be 0.0237.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023708232449603735"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Euclidean_distance[100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Everything seems to check out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now you are ready to write a function that computes the distances from a query house to all training houses. \n",
    "# The function should take two parameters: \n",
    "# (i) the matrix of training features and (ii) the single feature vector associated with the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So lets modify our Euclidean_distance to Euclidean_distanceV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Euclidean_distanceV1(FeatureMatrix, Query):\n",
    "        # Get the difference between your query house and each house in the data set\n",
    "        Difference = FeatureMatrix - Query\n",
    "        # Square those differences\n",
    "        Squared_Differences = Difference ** 2\n",
    "        # Get the sum of squared differences\n",
    "        # You want to get sum row by row for each house ; hence setting the axis \n",
    "        Sum_of_squared_differences = np.sum(Squared_Differences, axis=1)\n",
    "        # Get the Euclidean distance by taking the square root of the sum of squared differences\n",
    "        Euclidean_distance = np.sqrt(Sum_of_squared_differences)\n",
    "        return Euclidean_distance\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Result=Euclidean_distanceV1(features_train,features_test[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test to make sure my function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023708232449603735"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quiz: Take the query house to be third house of the test set (features_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Result=Euclidean_distanceV1(features_train,features_test[2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seems to work.\n",
    "# Our function returns back the Euclidean_distance\n",
    "# For 1-NN search, all we need to do is to return the house closest to our query\n",
    "# This means returning the house with the smallest distance in our Euclidean_distance result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So lets get the minimum value of our result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028604952675079271"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets also get the most important piece which is the index of that minimum\n",
    "# That tells us the exact house that gave this min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets return the indices of the 5 most similar houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 382, 1149, 4087, 3142, 2751])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result.argsort()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now lets use this index to find the price of the house and that will be the prediction of our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remenber when we used out get_ numpy function we returned two data:\n",
    "# One is the matrix we will use for prediction and the other is a vector\n",
    "# that contains the actual values of what we are trying to predict\n",
    "# In our case it is price and the data relevant to this analysis is the \n",
    "# output_train data which contains prices that match the houses in the features_train data set\n",
    "# All we have to do now is to find the 382th member and whatever that price is \n",
    "# becomes our predicted price for the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249000\n"
     ]
    }
   ],
   "source": [
    "print output_train[382]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Voila!!!! This is our prediction: 249000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So based on this, we can update our Euclidean_distanceV1 to do all this computation and return for us:\n",
    "# 1) The Minimum distance calculated\n",
    "# 2) The index of the Minimum distance\n",
    "# 3) The price attached to this index\n",
    "# However to do this we have to add one more input to the function : The output_array\n",
    "# This contains all the prices of the house and we will use it for predictions\n",
    "# We call this function Euclidean_distanceV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Euclidean_distanceV2(FeatureMatrix, Query,Output_array):\n",
    "        # Get the difference between your query house and each house in the data set\n",
    "        Difference = FeatureMatrix - Query\n",
    "        # Square those differences\n",
    "        Squared_Differences = Difference ** 2\n",
    "        # Get the sum of squared differences\n",
    "        # You want to get sum row by row for each house ; hence setting the axis \n",
    "        Sum_of_squared_differences = np.sum(Squared_Differences, axis=1)\n",
    "        # Get the Euclidean distance by taking the square root of the sum of squared differences\n",
    "        Euclidean_distance = np.sqrt(Sum_of_squared_differences)\n",
    "        \n",
    "        # Save minimum of Euclidean distance (Thats the minimum distance available)\n",
    "        MinimumDistance = min(Euclidean_distance)\n",
    "        \n",
    "        # Get the index of the minimum house in the array\n",
    "        Index_of_Minimum = Euclidean_distance.argmin()\n",
    "        \n",
    "        # Use that index to find the price of the house in the price array. This is called the Output_array\n",
    "        # in this function\n",
    "        Price = Output_array[Index_of_Minimum]\n",
    "        \n",
    "        # Now we print the results which includes\n",
    "        # 1) The Minimum distance calculated\n",
    "        # 2) The index of the Minimum distance\n",
    "        # 3) The price attached to this index\n",
    "        print MinimumDistance,Index_of_Minimum,Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00286049526751 382 249000\n"
     ]
    }
   ],
   "source": [
    "Euclidean_distanceV2(features_train, features_test[2],output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we have this function that takes three inputs and returns \n",
    "# the euclidean distance of the most similar house\n",
    "# the index of the most similar house\n",
    "# and the price of that house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So in summary, we took a query and a set of data\n",
    "# we calculated the euclidean distance of our query from each of the houses in our data set\n",
    "# then we found the most similar house to our query by finding the minimum distance\n",
    "# We then used that house to predict the price of our query house\n",
    "# This is basically the 1-NN search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now lets do a K-NN search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is conceptually the same with the 1-NN search\n",
    "# The difference here is that instead of returning the MOST similar house, we return a group of similar HOUSES.\n",
    "# The number of houses in the group is determined by the user and thats what the K stands for \n",
    "# So we will just have to modify our Euclidean_distanceV2 function \n",
    "# Instead of returning just one similar house\n",
    "# we return a k number of similar houses.\n",
    "# The k will be a parameter that the user will have to decide on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I had initially wanted to set up a for loop to through the Euclidean_distance\n",
    "# and in iteration do two things\n",
    "# One find the min\n",
    "# Save the index of that min in a list\n",
    "# Delete that from the array\n",
    "# and then find the next minimal value and repeat the process again\n",
    "# Repeat that k times.\n",
    "# That will work and you will get a list of k minimum values\n",
    "# However, the problem is in the indices which should match the indices of the original array\n",
    "# Our returned indices would not match because everytime we remove an item from the array,\n",
    "# the indexing is changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So I just resorted to using the numpy argument that returns the indices\n",
    "# of a k number of minimum items in an array i.e Result.argsort()[:5]\n",
    "# So I just modified the function Euclidean_distanceV2 to reflect that \n",
    "# and I called this modified function Euclidean_distanceKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Euclidean_distanceKNN(FeatureMatrix, Query,k):\n",
    "        # Get the difference between your query house and each house in the data set\n",
    "        Difference = FeatureMatrix - Query\n",
    "        # Square those differences\n",
    "        Squared_Differences = Difference ** 2\n",
    "        # Get the sum of squared differences\n",
    "        # You want to get sum row by row for each house ; hence setting the axis \n",
    "        Sum_of_squared_differences = np.sum(Squared_Differences, axis=1)\n",
    "        # Get the Euclidean distance by taking the square root of the sum of squared differences\n",
    "        Euclidean_distance = np.sqrt(Sum_of_squared_differences)\n",
    "        \n",
    "        # Get the index of the 5 minimum house in the array\n",
    "        Index_of_Minimum = Euclidean_distance.argsort()[:k]\n",
    "        \n",
    "        return Index_of_Minimum\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets test our new function that takes 3 parameters\n",
    "# the value of k;\n",
    "# the feature matrix for the training houses; and\n",
    "# the feature vector of the query house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 382, 1149, 4087, 3142, 2751])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Euclidean_distanceKNN(features_train,features_test[2] ,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quiz:\n",
    "# Take the query house to be third house of the test set (features_test[2]). \n",
    "# What are the indices of the 4 training houses closest to the query house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KNN=Euclidean_distanceKNN(features_train,features_test[2] ,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ok we now know how to return the indices of the most similar houses to our query\n",
    "# We can then use the prices of these similar houses to predict the price of our query house\n",
    "# There are many ways to do that and one simple way is just take the average of the prices of the most similar house\n",
    "# That average is then returned as the prediction for our query house\n",
    "# Now let modify our ...KNN function to do all this and return the predicted value \n",
    "# based on the average of the most similar house\n",
    "# We call this function Euclidean_distanceKNNv1 \n",
    "# Oh we also add the output array that we are going to use for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Euclidean_distanceKNNv1(FeatureMatrix, QueryMatrix,k,Output_array):\n",
    "        # Get the difference between your query house and each house in the data set\n",
    "        Difference = FeatureMatrix - QueryMatrix\n",
    "        # Square those differences\n",
    "        Squared_Differences = Difference ** 2\n",
    "        # Get the sum of squared differences\n",
    "        # You want to get sum row by row for each house ; hence setting the axis \n",
    "        Sum_of_squared_differences = np.sum(Squared_Differences, axis=1)\n",
    "        # Get the Euclidean distance by taking the square root of the sum of squared differences\n",
    "        Euclidean_distance = np.sqrt(Sum_of_squared_differences)\n",
    "        \n",
    "        # Get the index of the 5 minimum house in the array\n",
    "        Index_of_Minimum = Euclidean_distance.argsort()[:k]\n",
    "        \n",
    "        # Getting the prices of k similar houses\n",
    "        Prices=Output_array[[Index_of_Minimum]]\n",
    "        \n",
    "        # Getting the average of these prices as prediction for our query house\n",
    "        Prediction = np.mean(Prices)\n",
    "        \n",
    "        return Prediction\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quiz:\n",
    "# Again taking the query house to be third house of the test set (features_test[2]), \n",
    "# predict the value of the query house using k-nearest neighbors with k=4 \n",
    "# and the simple averaging method described and implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413987.5"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Euclidean_distanceKNNv1(features_train,features_test[2] ,4,output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pretty good huh! \n",
    "# The limitation of this function is that it only predicts one house\n",
    "# That is it takes the observations for just one house as query\n",
    "# and then goes through all our data set and find k most similar houses to our query\n",
    "# and then using the prices of the k most similar houses predicts the price of our query\n",
    "# Now what of if we have a set of houses that we need to predict\n",
    "# Well, we can use this function and do our prediction one by one for each house in our query set\n",
    "# That would work. However, it will even be better if we modified the function so that it does it for us\n",
    "# My fix for this is just to set up a for loop that will go through a vector and extract the \n",
    "# items in that vector one by one. In our case, this represents each houses in the query set\n",
    "# Once we can get each house one by one, then inside the for loop will just be the same computations\n",
    "# which will result in the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So for just one single house in a query looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01345102,  0.01163464,  0.01054359,  0.00906442,  0.00204821,\n",
       "        0.0085295 ,  0.        ,  0.        ,  0.0116321 ,  0.01216718,\n",
       "        0.00543458,  0.01867657,  0.01329154,  0.        ,  0.01348883,\n",
       "       -0.01346136,  0.00977293,  0.00252907])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Another example of just one query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01345102,  0.01163464,  0.00602491,  0.00650014,  0.00096311,\n",
       "        0.01279425,  0.        ,  0.        ,  0.01550947,  0.01390535,\n",
       "        0.00749834,  0.        ,  0.0131619 ,  0.        ,  0.0134871 ,\n",
       "       -0.01346925,  0.01009441,  0.00206058])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In both of these cases, we can use our function Euclidean_distanceKNNv1 \n",
    "# cos we are dealing with just one query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now this is an example of a query that contains 2 houses extracted from our feature_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Query = features_test[2:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01345102,  0.01163464,  0.01054359,  0.00906442,  0.00204821,\n",
       "         0.0085295 ,  0.        ,  0.        ,  0.0116321 ,  0.01216718,\n",
       "         0.00543458,  0.01867657,  0.01329154,  0.        ,  0.01348883,\n",
       "        -0.01346136,  0.00977293,  0.00252907],\n",
       "       [ 0.01345102,  0.01163464,  0.00602491,  0.00650014,  0.00096311,\n",
       "         0.01279425,  0.        ,  0.        ,  0.01550947,  0.01390535,\n",
       "         0.00749834,  0.        ,  0.0131619 ,  0.        ,  0.0134871 ,\n",
       "        -0.01346925,  0.01009441,  0.00206058]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Looking this shows an array of 2 rows, with each row containing 18 columns\n",
    "# With respect to our examples, each row represents a house and 18 features of the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can use the .shape function in numpy to determine the diimensions of our vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 18)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# That shows correctly that we have 2 houses with each house containing 18 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To go through the houses one by one , we can just use a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'New' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-7ed82020c52c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mNew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'New' is not defined"
     ]
    }
   ],
   "source": [
    "for i in xrange(len(Query)):\n",
    "    print New[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We modify our Euclidean_distanceKNNv1 by just adding a loop that will go through \n",
    "# the individual houses in the query set . In each for loop, we just do the computation to get the predictions as usual\n",
    "# We call this Euclidean_distanceKNNv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Euclidean_distanceKNNv2(FeatureMatrix, QueryMatrix,k,Output_array):\n",
    "        Predictions = []\n",
    "        for i in xrange(len(QueryMatrix)):\n",
    "            Query = QueryMatrix[i]\n",
    "            #print Query  # Lets print each of the query to make sure that we are looking at each house with the right\n",
    "                         # features\n",
    "            \n",
    "            # Once we are sure that the houses are being accessed correctly in the query set,\n",
    "            # we can now go ahead and do our regular computation that will return the prediction\n",
    "            # Get the difference between your query house and each house in the data set\n",
    "            Difference = FeatureMatrix - Query\n",
    "            # Square those differences\n",
    "            Squared_Differences = Difference ** 2\n",
    "            # Get the sum of squared differences\n",
    "            # You want to get sum row by row for each house ; hence setting the axis \n",
    "            Sum_of_squared_differences = np.sum(Squared_Differences, axis=1)\n",
    "            # Get the Euclidean distance by taking the square root of the sum of squared differences\n",
    "            Euclidean_distance = np.sqrt(Sum_of_squared_differences)\n",
    "        \n",
    "            # Get the index of the 5 minimum house in the array\n",
    "            Index_of_Minimum = Euclidean_distance.argsort()[:k]\n",
    "        \n",
    "            # Getting the prices of k similar houses\n",
    "            Prices=Output_array[[Index_of_Minimum]]\n",
    "        \n",
    "            # Getting the average of these prices as prediction for our query house\n",
    "            Prediction = np.mean(Prices)\n",
    "            \n",
    "            #print Prediction\n",
    "        \n",
    "            Predictions.append(Prediction)\n",
    "        \n",
    "        return Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now lets take this for a ride and test it out\n",
    "# Our houses that we want the predictions for are houses 2 and 3 in the feature_test matrix\n",
    "# So we specify that as features_test[2:4,]\n",
    "# Everything else remains the same in terms of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[413987.5, 552750.0]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Euclidean_distanceKNNv2(features_train,features_test[2:4,] ,4,output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Great!\n",
    "# We have printed the results of the function\n",
    "# We have the observations for each house printed and below it we have the predicted price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This works great.....except if we give it a query with just one house. \n",
    "# Now this where my lack of knowledge in data structures comes to haunt me\n",
    "# A one house query with this function results in the for loop going through\n",
    "# the features of the house one by one and thats not what we want\n",
    "# Below is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[583875.0,\n",
       " 504625.0,\n",
       " 467000.0,\n",
       " 336087.5,\n",
       " 242750.0,\n",
       " 312850.0,\n",
       " 196500.0,\n",
       " 196500.0,\n",
       " 504625.0,\n",
       " 526375.0,\n",
       " 195000.0,\n",
       " 713250.0,\n",
       " 521125.0,\n",
       " 196500.0,\n",
       " 583875.0,\n",
       " 218750.0,\n",
       " 323850.0,\n",
       " 242750.0]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Euclidean_distanceKNNv2(features_train,features_test[2] ,4,output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Yikes! This is just one house and it should just give me the prediction of that house\n",
    "# But the for loop interprets the features of that house (wehich is 18 by the way) as separate \n",
    "# and does computation for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instead of having one function that computes prediction for one house and a different function that computes\n",
    "# predictions for a bunch of houses, I decided to combine both functions as one.\n",
    "# All I have to do is to find a way to determine if my query matrix is just a 1D vector which means just one house in \n",
    "# in the query set or is it more than a 1D vector which means we have more than one house in the query set\n",
    "# To discriminate from this two possibilites, I took advantage of the .ndim function\n",
    "# .ndim returns the dimension of a vector\n",
    "# So if it returns 1, it means that you only have 1D . Other than that, it means more than 1D\n",
    "# An instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Query2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-cd8bbf29b7c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQuery2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Query2' is not defined"
     ]
    }
   ],
   "source": [
    "Query2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Query.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So i will modify the function and call it Euclidean_distanceKNNv3.\n",
    "# What it does is simple:\n",
    "# First it will ask if your vector is a 1D or not\n",
    "# If it is a 1D, then we just the function that deals with just one house in the query set (Euclidean_distanceKNNv1)\n",
    "# Else, we now assume that we have more than one house in the query set, and in that case\n",
    "# we call the other function that handles multiple predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Euclidean_distanceKNNv3(FeatureMatrix, QueryMatrix,k,Output_array):\n",
    "    \n",
    "    # Calculate dimensions of the QueryMatrix\n",
    "    Dimension = QueryMatrix.ndim\n",
    " \n",
    "    # Use that answer to determine what function to run\n",
    "    \n",
    "    if Dimension == 1:\n",
    "        # This means we only have one house in our query set\n",
    "        # Then run the function that works on only one house in the query\n",
    "        Prediction = Euclidean_distanceKNNv1(FeatureMatrix, QueryMatrix,k,Output_array)\n",
    "    else:\n",
    "        # This means now that we have a matrix with more than one house in the query set\n",
    "        # So we run the function for more than a house in the query set\n",
    "        Prediction = Euclidean_distanceKNNv2(FeatureMatrix, QueryMatrix,k,Output_array)\n",
    "    \n",
    "    return Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413987.5"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Euclidean_distanceKNNv3(features_train,features_test[2] ,4,output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[413987.5, 552750.0]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Euclidean_distanceKNNv3(features_train,features_test[2:4,:] ,4,output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quiz: Make predictions for the first 10 houses in the test set using k-nearest neighbors with k=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[881300.0,\n",
       " 431860.0,\n",
       " 460595.0,\n",
       " 430200.0,\n",
       " 766750.0,\n",
       " 667420.0,\n",
       " 350032.0,\n",
       " 512800.70000000001,\n",
       " 484000.0,\n",
       " 457235.0]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Euclidean_distanceKNNv3(features_train,features_test[0:10,:] ,10,output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quiz: What is the index of the house in this query set that has the lowest predicted value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer : Number 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quiz: What is the predicted value of this house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# $350032.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is pretty good\n",
    "# However, you can see in the first analysis I used 1 as the NN...subsequently I used 4 as my k\n",
    "# In the last analysis I used 10 as my k. \n",
    "# This begs the question....what is the right k to use????\n",
    "# That is determined empirically.\n",
    "# Thats why we have our training data set split into two: training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So to determine what k might be good, we predict the prices of all the houses in our validation set\n",
    "# using our training data set. We do this predictions for a range of k (eg set k to be from 1 to 15 or something)\n",
    "# So we now have all the predictions from all the different k.\n",
    "# The question now is which one is the most accurate of all\n",
    "# We will use the residual sum of squares as a measure of accuracy\n",
    "# To calculate the RSS, we have to save all the predictions in an array\n",
    "# Then get the difference between the predictions and the actual prices\n",
    "# Square them to get rid of signs\n",
    "# Take the sum of the squares and thats your RSS\n",
    "# You do that for all k's and then return the k that gives the minimal RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets first write a function that uses just one k,\n",
    "# Predicts prices based on this k\n",
    "# Calculates the RSS\n",
    "# Returns that value\n",
    "# We call that function best_k_finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_k_finder(FeatureMatrix, QueryMatrix,k,Output_array, Actual_Prices):\n",
    "    \n",
    "    # Lets first predict all the validation set from all the training set, setting k as 1\n",
    "    Prediction = Euclidean_distanceKNNv2(FeatureMatrix, QueryMatrix,k,Output_array)\n",
    "    \n",
    "    # Now that we have the predictions, we want to know how well our predictions did\n",
    "    # To do this we need to compute the RSS\n",
    "    # So first get the difference between our predictions and the actual prices we are trying to predict\n",
    "    # in our validation set\n",
    "    \n",
    "    Difference = Prediction - Actual_Prices\n",
    "    \n",
    "    # Get the squared difference\n",
    "    Squared_Difference = Difference ** 2\n",
    "    \n",
    "    # Get the sum of the squared difference\n",
    "    \n",
    "    RSS = Squared_Difference.sum()\n",
    "    \n",
    "    return RSS\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing it out with k set as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Predictions=best_k_finder(features_train,features_valid,1,output_train , output_valid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105453830251561.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we have a function that calculates the RSS for one particular k\n",
    "# All we have to do now is to set a loop that will calculate the RSS for a range of k's\n",
    "# Lets print all the RSS as we calculate it\n",
    "# All we have to do is to modify our best_k_finder and make it loop through a range of k's\n",
    "# In each loop, it does the same computation and then prints the RSS before going to the next k\n",
    "# We call this best_k_finder2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_k_finder2(FeatureMatrix, QueryMatrix,k,Output_array, Actual_Prices):\n",
    "    \n",
    "    for i in xrange(k):\n",
    "    \n",
    "        print (i)\n",
    "         # Lets first predict all the validation set from all the training set, setting k as 1\n",
    "        Prediction = Euclidean_distanceKNNv2(FeatureMatrix, QueryMatrix,i+1,Output_array)\n",
    "    \n",
    "         # Now that we have the predictions, we want to know how well our predictions did\n",
    "         # To do this we need to compute the RSS\n",
    "        # So first get the difference between our predictions and the actual prices we are trying to predict\n",
    "        # in our validation set\n",
    "    \n",
    "        Difference = Prediction - Actual_Prices\n",
    "    \n",
    "        # Get the squared difference\n",
    "        Squared_Difference = Difference ** 2\n",
    "    \n",
    "        # Get the sum of the squared difference\n",
    "    \n",
    "        RSS = Squared_Difference.sum()\n",
    "    \n",
    "        print (RSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets take it for a ride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1.05453830252e+14\n",
      "1\n",
      "8.3445073504e+13\n",
      "2\n",
      "7.26920960192e+13\n",
      "3\n",
      "7.19467216521e+13\n",
      "4\n",
      "6.98465174197e+13\n"
     ]
    }
   ],
   "source": [
    "Predictions=best_k_finder2(features_train,features_valid,5,output_train , output_valid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cool. However, we dont to just print all the RSS.\n",
    "# What we really want is to return the min RSS and the k vlaue that gave us this RSS\n",
    "# So again, lets modify our functiion to do this\n",
    "# We call this best_k_finder3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_k_finder3(FeatureMatrix, QueryMatrix,k,Output_array, Actual_Prices):\n",
    "    \n",
    "    RSS_List = []\n",
    "    for i in xrange(k):\n",
    "    \n",
    "        #print (i)\n",
    "         # Lets first predict all the validation set from all the training set, setting k as 1\n",
    "        Prediction = Euclidean_distanceKNNv2(FeatureMatrix, QueryMatrix,i+1,Output_array)\n",
    "    \n",
    "         # Now that we have the predictions, we want to know how well our predictions did\n",
    "         # To do this we need to compute the RSS\n",
    "        # So first get the difference between our predictions and the actual prices we are trying to predict\n",
    "        # in our validation set\n",
    "    \n",
    "        Difference = Prediction - Actual_Prices\n",
    "    \n",
    "        # Get the squared difference\n",
    "        Squared_Difference = Difference ** 2\n",
    "    \n",
    "        # Get the sum of the squared difference\n",
    "    \n",
    "        RSS = Squared_Difference.sum()\n",
    "    \n",
    "        RSS_List.append(RSS)\n",
    "    \n",
    "    MinimumRSS = min(RSS_List)\n",
    "    Index = RSS_List.index(MinimumRSS)\n",
    "    print (MinimumRSS)\n",
    "    print (RSS_List)\n",
    "    print Index + 1\n",
    "    return RSS_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.98465174197e+13\n",
      "[105453830251561.0, 83445073504025.5, 72692096019202.562, 71946721652091.688, 69846517419718.602]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "Predictions=best_k_finder3(features_train,features_valid,5,output_train , output_valid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[105453830251561.0,\n",
       " 83445073504025.5,\n",
       " 72692096019202.562,\n",
       " 71946721652091.688,\n",
       " 69846517419718.602]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So instead of returning the minimal RSS and the index, we can just plot it\n",
    "# We have saved all the RSS in the variable called Predictions\n",
    "# And we know th range of the k that we used\n",
    "# So we can plot the all the RSS versus the k values\n",
    "# The matplot function does that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x122cfc690>]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEGCAYAAACNaZVuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb2ZWg/4/9rBIT9oLdJ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12352a790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "kvals = range(1, 6)\n",
    "plt.plot(kvals, Predictions,'bo-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets repeat this using 15 as k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.73616787355e+13\n",
      "[105453830251561.0, 83445073504025.5, 72692096019202.562, 71946721652091.688, 69846517419718.602, 68899544353180.836, 68341973450051.094, 67361678735491.5, 68372727958976.094, 69335048668556.742, 69523855215598.828, 69049969587246.172, 70011254508263.688, 70908698869034.344, 71106928385945.156]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "Predictions=best_k_finder3(features_train,features_valid,15,output_train , output_valid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x122c3efd0>]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEGCAYAAACJnEVTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nivx/S8dp9DmhFosAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123ae3450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "kvals = range(1, 16)\n",
    "plt.plot(kvals, Predictions,'bo-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What is the RSS on the TEST data using the value of k found above? To be clear, sum over all houses in the TEST set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Predictions=best_k_finder(features_train,features_test,8,output_train , output_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133118823551516.81"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
